# Satellite Data Collection Pipeline

This pipeline continuously collects and processes satellite imagery data for the county visualization app, allowing for temporal analysis of growth potential and obsolescence metrics.

## Directory Structure

- `src/` - Source code for data collection and processing
  - `collectors/` - Data collection modules (satellite API interfaces)
  - `processors/` - Data processing modules (feature extraction, scoring)
  - `utils/` - Utility functions and helpers
  - `api/` - API server for time-series data access
  - `dashboard/` - Web dashboard for visualizing time-series data
- `config/` - Configuration files (API keys, processing parameters)
- `data/` - Data storage
  - `raw/` - Raw satellite data (organized by timestamp)
  - `processed/` - Processed county scores (time-series data)
- `scripts/` - Operational scripts for scheduling and maintenance
- `logs/` - Log files generated by pipeline components

## Features

- **Continuous Data Collection**: Automated collection of satellite imagery data from Google Earth Engine
- **Metrics Processing**: Extract growth potential and obsolescence scores from satellite data
- **Time-Series Storage**: Store county metrics over time for trend analysis
- **API Access**: RESTful API for accessing processed time-series data
- **Dashboard Visualization**: Web-based dashboard for visualizing county metrics over time
- **Historical Processing**: Batch processing for historical satellite imagery
- **Parallel Processing**: Support for multi-process execution for faster historical data analysis

## Requirements

- Python 3.8+
- Google Earth Engine API access
- Required Python packages listed in requirements.txt

## Getting Started

1. Install dependencies:
   ```
   pip install -r requirements.txt
   ```

2. Configure your Google Earth Engine credentials:
   ```
   cp config/gee_credentials.example.json config/gee_credentials.json
   # Edit the file with your credentials
   ```

3. Run a test collection:
   ```
   ./run.sh collect --test
   ```

## Usage

### Running Components

The pipeline includes a convenient runner script that can launch different components:

```
./run.sh [command]
```

Available commands:
- `collect [options]` - Run data collection for the most recent time period
- `historical [options]` - Process historical data
- `api` - Start the API server
- `dashboard` - Start the dashboard server
- `all` - Start API and dashboard servers
- `help` - Show help message

Examples:
```
# Run a test collection
./run.sh collect --test

# Process historical data for a specific time range
./run.sh historical --start-date 2020-01-01 --end-date 2023-12-31 --interval quarterly

# Start all services (API and dashboard)
./run.sh all
```

### Scheduled Data Collection

Set up a cron job to run the collection script regularly. An example crontab configuration is provided in `config/crontab.example`:

```
# Copy the example crontab and edit as needed
cp config/crontab.example mycrontab
vim mycrontab

# Install the crontab
crontab mycrontab
```

### Processing Historical Data

To process historical satellite data for counties over a specific time period:

```
python scripts/process_historical.py --start-date 2020-01-01 --end-date 2023-12-31 --interval quarterly
```

Options:
- `--counties` - Comma-separated list of county FIPS codes
- `--all-counties` - Process all counties in the shapefile
- `--state` - Process all counties in a state (state FIPS code)
- `--interval` - Time interval for processing (monthly, quarterly, yearly)
- `--parallel` - Number of parallel processes to use

### Accessing the API

Once the API server is running, you can access the following endpoints:

- `GET /api/v1/counties` - List all counties with available data
- `GET /api/v1/time_series/{county_fips}` - Get time series data for a county
- `GET /api/v1/latest/{county_fips}` - Get the latest data point for a county
- `GET /api/v1/metrics?date={date}&metric={metric}` - Get a specific metric for all counties at a specific date

### Using the Dashboard

The dashboard provides a visual interface for exploring county metrics over time:

1. Start the dashboard: `./run.sh dashboard`
2. Open a web browser and navigate to: `http://localhost:5000`
3. Select a county and date range to view the metrics charts

## Architecture

The pipeline follows a modular approach:

1. **Collection** (`gee_collector.py`) - Fetches raw satellite imagery from Google Earth Engine
2. **Processing** (`metrics_processor.py`) - Extracts features and calculates county-level metrics
3. **Storage** (`time_series.py`) - Stores processed data in time-series format
4. **API** (`server.py` in api/) - Provides processed data to the visualization app
5. **Dashboard** (`server.py` in dashboard/) - Visualizes time-series data for analysis

## Integration with County Visualization App

The processed data can be integrated with the main county visualization app through the time-series API. The API provides endpoints for retrieving the latest metrics or historical trends for any county.

To configure the county visualization app to use this pipeline's data:

1. Ensure the API server is running: `./run.sh api`
2. Configure the county visualization app to fetch metrics from the API endpoints
3. Implement a time slider in the visualization app using the time-series data

## Performance Considerations

- For large-scale processing, use the `--parallel` option with `process_historical.py`
- Raw satellite data can be large; implement the cleanup task from the crontab example
- For production deployments, consider using a proper process manager (like systemd, supervisor, or PM2) instead of the basic run script

## License

This project is licensed under the same terms as the main county visualization app.